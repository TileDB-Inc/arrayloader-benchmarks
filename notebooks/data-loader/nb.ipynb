{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10226200-1b99-4758-a9fb-1c7f741c70e3",
   "metadata": {},
   "source": [
    "# Plot: samples/sec vs. memory use\n",
    "- `alb data-loader` appends rows to [epochs.parquet](./epochs.parquet)\n",
    "- `alb data-loader-nb` executes this notebook on a given slice of that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be02d7f-9cc1-47b5-b89e-bd3d1a2fedd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utz\n",
    "from utz import *\n",
    "from utz.plots import symbols\n",
    "from benchmarks.cli.data_loader import DEFAULT_PQT_PATH, CHUNK_METHODS\n",
    "from benchmarks.cli.data_loader_nb import DEFAULT_MARKER_SIZE_ANCHOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd3aa6-d6e8-4022-b130-9521898e9987",
   "metadata": {},
   "source": [
    "[Papermill](https://papermill.readthedocs.io/en/latest/) parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f69780-67fa-4c2b-bf1e-0d8b7b411163",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "db_path = DEFAULT_PQT_PATH  # Parquet path to read epoch stats from\n",
    "out_dir = None              # Directory to save plot PNG/JSON to (e.g. \"m3\", \"azl\")\n",
    "host = None                 # Description of host the stats were collected on, used in plot subtitle (e.g. \"M3 Mac\", \"Amazon Linux\")\n",
    "show = \"html\"               # Set to \"png\" to render plots in notebook as PNGs (good for noninteractive mode / Git-committing)\n",
    "hostname_rgx = None         # Filter DB \"hostname\" field to values matching this regex\n",
    "max_batches = None          # Filter DB `max_batches` column\n",
    "since = None                # Filter DB to `alb_start` since this datetime\n",
    "instance_type = None        # Filter to runs on this EC2 instance type\n",
    "sorted_datasets = None      # Filter DB based on `sorted_datasets`\n",
    "legend_orientation = None   # Orient legends vertically (\"v\") or horizontally (\"h\")\n",
    "marker_opacity = 0.8        # Marker opacity\n",
    "marker_size_anchor = None   # Scale marker sizes such that their areas are proportional to `block_size`, above and below this \"anchor\" value\n",
    "uri_rgx = None              # Filter DB \"uri\" field to values matching this regex\n",
    "start_idx = None            # Filter DB to runs consuming dataset slices beginning at this index\n",
    "end_idx = 123               # Filter DB to runs consuming dataset slices ending at this index\n",
    "W = 1000                    # Output plot width\n",
    "H =  600                    # Output plot height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c55209-da36-49cd-bb79-53103e5ea556",
   "metadata": {},
   "outputs": [],
   "source": [
    "if marker_size_anchor is None:\n",
    "    marker_size_anchor = DEFAULT_MARKER_SIZE_ANCHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c586037-7df1-4217-9b25-4f57da57a2ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(db_path)\n",
    "if hostname_rgx:\n",
    "    df = df[df.hostname.str.contains(hostname_rgx)].reset_index(drop=True).copy()\n",
    "if since:\n",
    "    since = to_dt(since)\n",
    "    df = df[df.alb_start >= since].reset_index(drop=True).copy()\n",
    "if instance_type:\n",
    "    df = df[df.instance_type == instance_type].copy()\n",
    "if uri_rgx:\n",
    "    df = df[~df.uri.isna()]\n",
    "    df = df[df.uri.str.contains(uri_rgx)].reset_index(drop=True).copy()\n",
    "if start_idx is not None:\n",
    "    df = df[df.start_idx == start_idx].reset_index(drop=True).copy()\n",
    "if end_idx is not None:\n",
    "    df = df[df.end_idx == end_idx].reset_index(drop=True).copy()\n",
    "if max_batches is not None:\n",
    "    df = df[df.max_batches == max_batches].copy()\n",
    "if sorted_datasets is not None:\n",
    "    df = df[df.sorted_datasets == sorted_datasets].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f0bf0-e4de-4aba-af55-06fb3caacad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df[['uri', 'chunk_method', 'chunks_per_block', 'chunk_size']].value_counts().sort_index().rename('num')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6e9fa-47e5-4161-9f15-2b1b57f2b3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pivoted = hist.reset_index(level=[0,1]).pivot(columns=['uri', 'chunk_method'], values='num')\n",
    "# assert (pivoted == 5).all().all()\n",
    "pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bfe89-73fa-4c81-b821-be35eb57cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chunk_lg2'] = df.chunk_size.apply(log2)\n",
    "chunk_lg2_vals = df.chunk_lg2.apply(int).unique().tolist()\n",
    "chunk_lg2_vals.sort()\n",
    "min_chunk_log2, max_chunk_log2 = min(chunk_lg2_vals), max(chunk_lg2_vals)\n",
    "min_chunk_log2, max_chunk_log2, chunk_lg2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c198cf0-6fa9-4515-93e9-ab98db77b4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['block_chunks_lg2'] = df.chunks_per_block.apply(log2).apply(int)\n",
    "counts_lg2_vals = df.block_chunks_lg2.unique().tolist()\n",
    "counts_lg2_vals.sort()\n",
    "min_block_chunks_lg2, max_block_chunks_lg2 = min(counts_lg2_vals), max(counts_lg2_vals)\n",
    "min_block_chunks_lg2, max_block_chunks_lg2, counts_lg2_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5aec0e-f9f5-460d-abdf-6d93acff54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_td(e):\n",
    "    s = int(e)\n",
    "    h = s // 3600\n",
    "    m = s // 60 % 60\n",
    "    s = s % 60\n",
    "    rv = ''\n",
    "    if h:\n",
    "        rv += f'{h}h'\n",
    "    if h or m:\n",
    "        rv += f'{m}m'\n",
    "    if s:\n",
    "        rv += f'{s}s'\n",
    "    return rv\n",
    "\n",
    "df['elapsed_str'] = df.elapsed.apply(fmt_td)\n",
    "df['start_dt_str'] = df.start_dt.dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa800f16-4921-4317-b32c-1f6d6b8a2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_count_to_size = (\n",
    "    df\n",
    "    [['chunk_size', 'chunks_per_block']]\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .index\n",
    "    .to_frame()\n",
    "    .reset_index(drop=True, level=0)\n",
    "    .chunk_size\n",
    "    .to_dict()\n",
    ")\n",
    "chunk_count_to_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36875032-579e-4581-b34c-3b0dd0120bfd",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 'SOMA chunk size'\n",
    "N = 'Chunks per shuffle block'\n",
    "S = 'Samples / sec'\n",
    "df[C] = pd.Categorical(df.chunk_size.apply(lambda c: f'{c:,}'))\n",
    "df[N] = pd.Categorical(df.chunks_per_block.apply(lambda c: f'{c:,}'))\n",
    "chunk_sizes = df[C].unique()\n",
    "chunks_per_blocks = df[N].unique()\n",
    "df[S] = df.n_rows / df.elapsed\n",
    "M = 'Max. memory usage'\n",
    "df = df.rename(columns={ 'max_mem': M, 'chunk_method': 'Method', })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6ea15-5042-4f54-ac1e-fcf246b0f236",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = singleton(df.batch_size.unique())\n",
    "print(f'{batch_size=}')\n",
    "n_vars = singleton(df.n_cols.unique())\n",
    "print(f'{n_vars=}')\n",
    "n_rows = singleton(df.n_rows.unique())\n",
    "print(f'{n_rows=}')\n",
    "total_rows = singleton(df.total_rows.unique())\n",
    "print(f'{total_rows=}')\n",
    "uri = singleton(df.uri.unique())\n",
    "print(f'{uri=}')\n",
    "instance_types = df.instance_type.unique().tolist()\n",
    "print(f'{instance_types=}')\n",
    "max_batches = singleton(df.max_batches.unique())\n",
    "print(f'{max_batches=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327af7e-b79b-4a75-9b20-ef08beea2984",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "host_str = f\"EC2 ({', '.join(instance_types)}), \" if instance_types else \"\"\n",
    "host_subtitle = f'{host_str}{batch_size} samples per PyTorch batch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66b31a-30c0-4081-828d-f3edacb632dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if total_rows == n_rows:\n",
    "    dataset_subtitle = f'{n_rows:,} cells'\n",
    "else:\n",
    "    assert max_batches\n",
    "    dataset_subtitle = f'{max_batches:,} batches ({n_rows:,} cells, from {total_rows:,} total)'\n",
    "dataset_subtitle += ', '\n",
    "if not uri:\n",
    "    dataset_subtitle += f'streamed (and sliced on the fly) from S3'\n",
    "elif uri.startswith('s3://'):\n",
    "    dataset_subtitle += f'pre-sliced, read from S3'\n",
    "else:\n",
    "    dataset_subtitle += f'pre-sliced, read from local disk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3aba52-95ba-4797-a634-e37bef4e3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    fig,\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    return utz.plot(\n",
    "        fig,\n",
    "        *args,        \n",
    "        dir=out_dir,\n",
    "        w=W, h=H,\n",
    "        show=show,\n",
    "        html=True,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd840aa-3113-49d8-b72d-043d72f212fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Samples/sec vs. memory use\"\n",
    "\n",
    "def ticktext(e):\n",
    "    chunk_count = int(2**e)\n",
    "    return f'{chunk_count:,}'\n",
    "\n",
    "tickvals = counts_lg2_vals\n",
    "colorbar = dict(\n",
    "    title=utz.plots.title(['# Chunks', 'per shuffled block']),\n",
    "    tickmode='array',\n",
    "    tickvals=tickvals,\n",
    "    ticktext=list(map(ticktext, tickvals)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f06a47-27a1-4868-b81c-77bf45072c33",
   "metadata": {},
   "source": [
    "Scale marker size to indicate shuffled block size (`chunk_size` * `chunks_per_block`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144bd96-d337-4169-a394-2f0af2a46d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_block_size, anchor_marker_size = map(int, marker_size_anchor.split('=', 1))\n",
    "anchor_block_size, anchor_marker_size\n",
    "\n",
    "def marker_size(block_size):\n",
    "    return anchor_marker_size * sqrt(block_size / anchor_block_size)\n",
    "\n",
    "df['marker_size'] = df.block_size.apply(marker_size)\n",
    "block2marker_size = df[['block_size', 'marker_size']].drop_duplicates().set_index('block_size').marker_size.to_dict()\n",
    "block2marker_size = { b: block2marker_size[b] for b in sorted(block2marker_size) }\n",
    "marker_sizes = list(block2marker_size.values())\n",
    "block2marker_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399836ca-c15f-4221-a220-8788abc2c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "def dummy_trace(name, legend=None, **kwargs):\n",
    "    marker = dict(color='gray')\n",
    "    marker.update(kwargs)\n",
    "    return go.Scatter(\n",
    "        name=name,\n",
    "        legend=legend,\n",
    "        x=[None], y=[None], mode='markers',\n",
    "        marker=marker,\n",
    "    )\n",
    "\n",
    "def legend(title, **kwargs):\n",
    "    defaults = dict(\n",
    "        xanchor='left',\n",
    "        yanchor='top',\n",
    "        bordercolor=\"Black\",\n",
    "        borderwidth=2,\n",
    "        #bgcolor=\"rgba(0,0,0,0)\",\n",
    "    )\n",
    "    defaults.update(kwargs)\n",
    "    return dict(\n",
    "        title_text=title,\n",
    "        **defaults\n",
    "    )\n",
    "\n",
    "customdata_cols = [\n",
    "    'chunk_size',\n",
    "    'chunks_per_block',\n",
    "    'block_size',\n",
    "    'instance_type',\n",
    "    'instance_id',\n",
    "    'start_dt_str',\n",
    "    'elapsed_str',\n",
    "]\n",
    "# Helper for customdata interpolation below\n",
    "c = {\n",
    "    col: \"%%{customdata[%d]}\" % idx\n",
    "    for idx, col in enumerate(customdata_cols)\n",
    "}\n",
    "\n",
    "for idx, chunk_method in enumerate(CHUNK_METHODS):\n",
    "    f = df[df.Method == chunk_method]\n",
    "    symbol = symbols[idx]\n",
    "    marker = dict(\n",
    "        color=f.block_chunks_lg2,\n",
    "        colorscale=px.colors.diverging.Portland,\n",
    "        cmin=min_block_chunks_lg2,\n",
    "        cmax=max_block_chunks_lg2 + .15,\n",
    "        colorbar=colorbar,\n",
    "        opacity=marker_opacity,\n",
    "        showscale=True,\n",
    "        size=f.marker_size,\n",
    "        symbol=symbol,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        name=chunk_method,\n",
    "        x=f[M],\n",
    "        y=f[S],\n",
    "        mode='markers',\n",
    "        marker=marker,\n",
    "        customdata=f[customdata_cols],\n",
    "        showlegend=False,\n",
    "    ))\n",
    "\n",
    "    # Dummy traces, for legend: one per fmt, set color/size (instead of inheriting from last data point in `f`)\n",
    "    size = marker_sizes[-1]\n",
    "    fig.add_trace(dummy_trace(\n",
    "        chunk_method,\n",
    "        size=size,\n",
    "        symbol=symbol,\n",
    "    ))\n",
    "\n",
    "# Dummy legend/traces for `block_size` facet (represented by marker size)\n",
    "if len(marker_sizes) > 1:\n",
    "    for block_size, marker_size in block2marker_size.items():\n",
    "        fig.add_trace(dummy_trace(\n",
    "            f\"{block_size:,}\",\n",
    "            legend=\"legend2\",\n",
    "            size=marker_size,\n",
    "            #symbol=symbols[0],\n",
    "        ))\n",
    "\n",
    "method_block_legends_v = dict(\n",
    "    legend =legend('Method',     x=.01, y=.99, ),\n",
    "    legend2=legend('Block size', x=.01, y=.81, ),\n",
    ")\n",
    "method_block_legends_h = dict(\n",
    "    legend =legend('Method',     x=.145, y=.99, ),\n",
    "    legend2=legend('Block size', x=.01,  y=.99, ),\n",
    ")\n",
    "if legend_orientation is None:\n",
    "    legend_orientation = 'v'\n",
    "method_block_legends = method_block_legends_v if legend_orientation == 'v' else method_block_legends_h\n",
    "\n",
    "legends = method_block_legends\n",
    "\n",
    "fig = plot(\n",
    "    fig,\n",
    "    utz.plots.title([\n",
    "        title,\n",
    "        host_subtitle,\n",
    "        dataset_subtitle,\n",
    "    ], subtitle_size=\"0.7em\"),\n",
    "    title_y=.95,\n",
    "    name=\"speed_vs_mem_1\",\n",
    "    hovertemplate=[\n",
    "        \"%s (%s)\" % (c['start_dt_str'], c['elapsed_str']),\n",
    "        \"%s (%s)\" % (c['instance_id'], c['instance_type']),\n",
    "        \"%s: %s\" % (C, c['chunk_size']),\n",
    "        \"Chunks per shuffled block: %s\" % c['chunks_per_block'],\n",
    "        \"Shuffled block size: %s\" % c['block_size'],\n",
    "        \"Samples/sec: %{y:,d}\",\n",
    "        \"Memory: %{x:.3s}\",\n",
    "    ],\n",
    "    xtitle=M,\n",
    "    xaxis_tickformat='s',\n",
    "    xaxis_rangemode='tozero',\n",
    "    ytitle=S,\n",
    "    **legends,\n",
    "    zerolines='y',\n",
    ")\n",
    "fig\n",
    "#from IPython.display import HTML\n",
    "#HTML(fig.to_html(include_plotlyjs='cdn'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
