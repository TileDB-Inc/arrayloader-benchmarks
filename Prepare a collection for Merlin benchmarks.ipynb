{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41a2e1c-11de-4852-8bb7-667a1243bd19",
   "metadata": {},
   "source": [
    "# Prepare a collection for Merlin benchmarks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d860802-e991-4f92-9df6-6c90d81e2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "!lamin load laminlabs/arrayloader-benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e440f3f-015f-44d7-acd8-d93f6625781d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lamindb as ln\n",
    "import anndata as ad\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770eacb-8d71-464c-a13e-65e47f8fbcca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ln.track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f8d8b-8333-465c-bd13-6e045c2e84f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection = ln.Collection.filter(uid=\"1gsdckxvOvIjQgeDVS1F\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc94aec-1c90-4b8f-8fa0-98d0e5b63283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad0dc4-6b68-4637-b79f-588f8c8fd80d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with collection.mapped(join=\"inner\") as ds:\n",
    "    var_inner = ds.var_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604a4ce-7bf3-4748-9e15-323f399ab9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_inner = var_inner[:20000].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddf732-f939-4c5c-9b10-72ea12ce22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_processed = []\n",
    "for artifact in tqdm(collection.artifacts):\n",
    "    print(artifact.key)\n",
    "    with artifact.backed() as access:\n",
    "        # todo: check why this error happens\n",
    "        # TypeError: Indexing elements must be in increasing order\n",
    "        # via selection of named varibales\n",
    "        # access[:, var_inner].to_memory()\n",
    "        # for the second artifact 0325478a-9b52-45b5-b40a-2e2ab0d72eb1.h5ad\n",
    "        # ok, it seems it doens't work with non-increasing indices\n",
    "        # todo: fix\n",
    "        idx_sort, reverse = np.unique(access.var_names.get_indexer(var_inner), return_inverse=True)\n",
    "        adata = access[:, idx_sort].to_memory()[:, reverse]\n",
    "    assert all(adata.var_names == var_inner)\n",
    "    print(\"adata loaded\")\n",
    "    artifact_processed = ln.Artifact(adata, description=artifact.description + \" subset of 20k vars\")\n",
    "    artifact_processed.save()\n",
    "    artifacts_processed.append(artifact_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1271380",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_inner = ln.Collection(\n",
    "    artifacts_processed, \n",
    "    name=collection.name + \" inner join and subset of 20k vars.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f70f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_inner.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8439731",
   "metadata": {},
   "source": [
    "## Prepare parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_inner = ln.Collection.filter(name__icontains=\" inner join and subset of 20k vars.\").one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6339fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster(n_workers=1, threads_per_worker=4)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661cdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def read_X(path, idx):\n",
    "    return ad.read_h5ad(path, backed=\"r\").X[idx, :].toarray().astype(\"float32\", copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of files per parquet file\n",
    "CHUNK_SIZE = 32768\n",
    "# row group size of parquet files\n",
    "ROW_GROUP_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_chunks = []\n",
    "chunk_sizes = []\n",
    "\n",
    "for artifact in collection_inner.artifacts:\n",
    "    with artifact.backed() as access:\n",
    "        n_obs = access.shape[0]\n",
    "    idx_splits = np.array_split(np.arange(n_obs), np.ceil(n_obs / CHUNK_SIZE))\n",
    "    for idx in idx_splits:\n",
    "        array_chunks.append(read_X(artifact.stage().as_posix(), idx))\n",
    "        chunk_sizes.append(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491513cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = da.concatenate([\n",
    "    da.from_delayed(chunk, (shape, len(var_inner)), dtype=\"float32\") \n",
    "    for chunk, shape in zip(array_chunks, chunk_sizes)\n",
    "]).rechunk((CHUNK_SIZE, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a68128",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def convert_to_dataframe(x, start, end):\n",
    "    return pd.DataFrame(\n",
    "        {'X': [arr.squeeze().astype(\"float32\", copy=False) for arr in np.vsplit(x, x.shape[0])]},\n",
    "        index=pd.RangeIndex(start, end)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bc131",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = [0] + list(np.cumsum(X.chunks[0]))[:-1]\n",
    "end_index = list(np.cumsum(X.chunks[0]))\n",
    "# calculate divisons for dask dataframe\n",
    "divisions = [0] + list(np.cumsum(X.chunks[0]))\n",
    "divisions[-1] = divisions[-1] - 1\n",
    "ddf = dd.from_delayed(\n",
    "    [\n",
    "        convert_to_dataframe(arr, start, end) for arr, start, end in \n",
    "        zip(X.to_delayed().flatten().tolist(), start_index, end_index)\n",
    "    ],\n",
    "    divisions=divisions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe696b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_parquet(\n",
    "    \"./merlin_benchmark\", \n",
    "    engine='pyarrow',\n",
    "    schema=pa.schema([('X', pa.list_(pa.float32()))]),\n",
    "    write_metadata_file=True,\n",
    "    row_group_size=ROW_GROUP_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da15ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_parquet = ln.Artifact(\"./merlin_benchmark\", description=collection_inner.name + \" counts in parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_parquet.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb7dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbproject": {
   "id": "GjHlkZOA4wKp",
   "parent": null,
   "pypackage": null,
   "time_init": "2024-01-24T10:59:26.707959+00:00",
   "user_handle": null,
   "user_id": null,
   "user_name": null,
   "version": "1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
